{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, a Multi Agent Deep Deterministic Policy Gradients (MADDPG) algorithim is used to train agents in a continous action space.\n",
    "\n",
    "Hyperparameters\n",
    "\n",
    "- BUFFER_SIZE = int(1e6)\n",
    "- BATCH_SIZE = 128        \n",
    "- GAMMA = 0.99            \n",
    "- TAU = 1e-3             \n",
    "- LR_ACTOR = 1e-3        \n",
    "- LR_CRITIC = 1e-3   \n",
    "- WEIGHT_DECAY = 0\n",
    "- LEARN_PASS = 5\n",
    "\n",
    "Actor-Critic networks are created with the following fully connected layers\n",
    "\n",
    "- Actor: 256 > 128\n",
    "\n",
    "- Critic: 256 > 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untrained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/colab_random.gif\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/colab_solved.gif\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Reward Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/collab_plot.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviroment solved in 558 episodes with avg_score = 0.51\tTime Elapsed: 0:18:37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Improvement Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate seemed to work out well with lower settings, however the time to keeps learning increased.  Experimenting with the hyperparameters and actor ciritc models will lead to better improvements.  Looking at other actor critic methods such as PPO or AC2 may yield intereting results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
